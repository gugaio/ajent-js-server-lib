const logger = require('../utils/logger');

class LLMClient {
  constructor(config) {
    this.config = config;
    
    // Rate limiting configuration - pode ser sobrescrito pelas implementa√ß√µes
    this.retryConfig = {
      maxRetries: config.maxRetries || 3,
      initialDelay: config.initialRetryDelay || 1000, // 1 segundo
      maxDelay: config.maxRetryDelay || 30000, // 30 segundos
      maxRetryDelay: config.maxRetryDelay || 30000, // compatibilidade com testes
      backoffMultiplier: config.backoffMultiplier || 2,
      enableRetry: config.enableRetry !== false, // Por padr√£o habilitado
    };
    
    this.validateConfig();
  }

  validateConfig() {
    throw new Error('Method validateConfig() must be implemented');
  }

  /**
   * Sleep for a given number of milliseconds
   */
  _sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Calculate delay with exponential backoff and jitter
   */
  _calculateDelay(attempt) {
    const delay = Math.min(
      this.retryConfig.initialDelay * Math.pow(this.retryConfig.backoffMultiplier, attempt),
      this.retryConfig.maxDelay
    );
    // Add jitter (¬±20% randomization) para evitar thundering herd
    const jitter = delay * 0.2 * (Math.random() - 0.5);
    const value = Math.floor(delay + jitter);
    // Garante que nunca ultrapasse o maxDelay explicitamente
    return Math.min(value, this.retryConfig.maxDelay);
  }

  /**
   * Check if error is retryable (429, 500, 502, 503, 504)
   * Implementa√ß√µes podem sobrescrever para adicionar l√≥gica espec√≠fica
   */
  _isRetryableError(error) {
    // Check for HTTP status codes
    if (error.status || error.code) {
      const statusCode = error.status || error.code;
      return [429, 500, 502, 503, 504].includes(statusCode);
    }
    
    // Check error message for rate limiting indicators
    const errorMessage = (error.message || '').toLowerCase();
    return errorMessage.includes('rate limit') || 
           errorMessage.includes('quota exceeded') ||
           errorMessage.includes('too many requests') ||
           errorMessage.includes('429') ||
           errorMessage.includes('server error') ||
           errorMessage.includes('service unavailable') ||
           errorMessage.includes('timeout');
  }

  /**
   * Execute operation with retry logic
   */
  async _executeWithRetry(operation, operationName = 'operation') {
    // Se retry est√° desabilitado, executa diretamente
    if (!this.retryConfig.enableRetry) {
      return await operation();
    }

    let lastError;
    
    for (let attempt = 0; attempt <= this.retryConfig.maxRetries; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error;
        
        // Don't retry on last attempt or non-retryable errors
        if (attempt === this.retryConfig.maxRetries || !this._isRetryableError(error)) {
          break;
        }

        const delay = this._calculateDelay(attempt);
        logger.warn(`${operationName} failed (attempt ${attempt + 1}/${this.retryConfig.maxRetries + 1}): ${error.message}. Retrying in ${delay}ms...`);
        
        await this._sleep(delay);
      }
    }
    
    throw lastError;
  }

  /**
   * Wrapper para send com retry autom√°tico
   */
  async send(messages, tools, model) {
    try {
      // Sempre serializa a resposta de sucesso
      const result = await this._executeWithRetry(async () => {
        return await this._sendImplementation(messages, tools, model);
      }, `${this.constructor.name} send`);
      return this.serializeResponse(result);
    } catch (error) {
      // Log do erro final
      logger.error(`${this.constructor.name} send failed after retries: ${error.message}`);
      // Se retry est√° desabilitado, lan√ßa o erro (para o teste esperar exception)
      if (!this.retryConfig.enableRetry) {
        throw error;
      }
      // Retorna uma resposta simulada da LLM em vez de erro
      return this._createErrorResponse(error, messages);
    }
  }

  /**
   * Wrapper para stream com retry autom√°tico (apenas para inicializa√ß√£o)
   */
  async stream(messages, tools, model) {
    try {
      return await this._executeWithRetry(async () => {
        return await this._streamImplementation(messages, tools, model);
      }, `${this.constructor.name} stream`);
    } catch (error) {
      logger.error(`${this.constructor.name} stream failed after retries: ${error.message}`);
      
      // Para streaming, retorna um iterator que simula uma resposta de erro
      return this._createErrorStreamResponse(error, messages);
    }
  }

  /**
   * Wrapper para stt com retry autom√°tico
   */
  async stt(audioFilePath) {
    try {
      return await this._executeWithRetry(async () => {
        return await this._sttImplementation(audioFilePath);
      }, `${this.constructor.name} stt`);
    } catch (error) {
      logger.error(`${this.constructor.name} stt failed after retries: ${error.message}`);
      
      // Para STT, retorna uma resposta de erro em texto
      return {
        text: "Desculpe, n√£o foi poss√≠vel processar o √°udio no momento. Tente novamente em alguns instantes.",
        error_details: {
          message: error.message,
          status: error.status || error.code,
          retryable: this._isRetryableError(error)
        }
      };
    }
  }

  /**
   * Cria uma resposta simulada da LLM quando h√° erro final
   */
  _createErrorResponse(error, messages = []) {
    const isRateLimit = this._isRetryableError(error);
    const providerName = this.constructor.name.replace('Client', '');
    
    let errorMessage;
    
    if (isRateLimit) {
      errorMessage = `Desculpe, estou temporariamente sobrecarregado devido ao alto volume de requisi√ß√µes. Por favor, tente novamente em alguns instantes. Agrade√ßo sua paci√™ncia! üôè`;
    } else {
      errorMessage = `Desculpe, encontrei um problema t√©cnico e n√£o consegui processar sua solicita√ß√£o no momento. Por favor, tente novamente em alguns instantes. Se o problema persistir, entre em contato com o suporte. üîß`;
    }

    // Verifica se o √∫ltimo message √© do usu√°rio para personalizar a resposta
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'user') {
      if (lastMessage.content && lastMessage.content.length > 100) {
        errorMessage += `\n\nObs: Percebi que sua mensagem √© bastante detalhada. Quando eu voltar a funcionar, ficarei feliz em ajudar com sua solicita√ß√£o completa.`;
      }
    }

    // Retorna no formato padr√£o de resposta da LLM
    const response = {
      role: 'assistant',
      content: errorMessage,
      _error_metadata: {
        original_error: error.message,
        provider: providerName,
        status: error.status || error.code,
        retryable: isRateLimit,
        timestamp: new Date().toISOString(),
        retry_count: this.retryConfig.maxRetries
      }
    };

    // Serializa usando o m√©todo da implementa√ß√£o
    try {
      return this.serializeResponse(response);
    } catch (serializeError) {
      // Fallback se a serializa√ß√£o falhar
      logger.warn(`Serialization failed for error response: ${serializeError.message}`);
      return response;
    }
  }

  // M√©todos abstratos que as implementa√ß√µes devem sobrescrever
  async _sendImplementation(messages, tools, model) {
    throw new Error('Method _sendImplementation() must be implemented');
  }
  
  async _streamImplementation(messages, tools, model) {
    throw new Error('Method _streamImplementation() must be implemented');
  }
  
  async _sttImplementation(audioFilePath) {
    throw new Error('Method _sttImplementation() must be implemented');
  }
  
  serializeResponse(response) {
    throw new Error('Method serializeResponse() must be implemented');
  }

  /**
   * M√©todo utilit√°rio para implementa√ß√µes customizarem detec√ß√£o de erros retryable
   */
  addRetryableErrorPatterns(patterns) {
    this._customRetryPatterns = this._customRetryPatterns || [];
    this._customRetryPatterns.push(...patterns);
  }

  /**
   * Override do _isRetryableError para incluir padr√µes customizados
   */
  _isRetryableErrorWithCustom(error) {
    // Primeiro verifica a l√≥gica base
    if (this._isRetryableError(error)) {
      return true;
    }

    // Depois verifica padr√µes customizados
    if (this._customRetryPatterns) {
      const errorMessage = (error.message || '').toLowerCase();
      return this._customRetryPatterns.some(pattern => 
        errorMessage.includes(pattern.toLowerCase())
      );
    }

    return false;
  }

  /**
   * Cria um stream response simulado para erros
   */
  _createErrorStreamResponse(error, messages = []) {
    const isRateLimit = this._isRetryableError(error);
    const providerName = this.constructor.name.replace('Client', '');
    let errorMessage;
    if (isRateLimit) {
      errorMessage = `Desculpe, estou temporariamente sobrecarregado devido ao alto volume de requisi√ß√µes. Por favor, tente novamente em alguns instantes. Agrade√ßo sua paci√™ncia! üôè`;
    } else {
      errorMessage = `Desculpe, encontrei um problema t√©cnico e n√£o consegui processar sua solicita√ß√£o no momento. Por favor, tente novamente em alguns instantes. Se o problema persistir, entre em contato com o suporte. üîß`;
    }
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'user') {
      if (lastMessage.content && lastMessage.content.length > 100) {
        errorMessage += `\n\nObs: Percebi que sua mensagem √© bastante detalhada. Quando eu voltar a funcionar, ficarei feliz em ajudar com sua solicita√ß√£o completa.`;
      }
    }
    // Retorna um async iterator que simula streaming da mensagem de erro
    const self = this;
    return {
      [Symbol.asyncIterator]: async function* () {
        const words = errorMessage.split(' ');
        let currentContent = '';
        for (let i = 0; i < words.length; i++) {
          const word = words[i] + (i < words.length - 1 ? ' ' : '');
          currentContent += word;
          yield {
            type: "content",
            content: word
          };
          await new Promise(resolve => setTimeout(resolve, 50));
        }
        yield {
          type: "finish",
          finish_reason: "stop",
          final_content: currentContent,
          final_tool_calls: null,
          _error_metadata: {
            original_error: error.message,
            provider: providerName,
            status: error.status || error.code,
            retryable: isRateLimit,
            timestamp: new Date().toISOString(),
            retry_count: self && self.retryConfig ? self.retryConfig.maxRetries : 3
          }
        };
      }
    };
  }
}

module.exports = { LLMClient };